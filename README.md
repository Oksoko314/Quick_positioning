# Quick_positioning
我们的新任务是年前提出的那一套东西 <快速回放功能>   
通过指定人及其相关动作，给出相关帧。  
技术方面的话，人员跟踪这里问题不大,(我们之前那套系统在这里依然可以使用，当然我更愿意去尝试最新的[DeepCC](https://github.com/ergysr/DeepCC))，主要在于对动作的判别。  
关于动作的判别，目前我想的是有两种路线，第一是通过单帧训练分类网络，也就是常见的CNN架构，如VGG、resnet，给出动作结果，第二条路线是通过提取骨架信息[st-gcn](https://github.com/yysijie/st-gcn)之后，通过时空图卷积网络进行分类。  
后者的优势在于运动的结果依赖于骨架信息，且利用到了时间的上下文信息。劣势在于如何建立基于排球运动类型的数据库，这个工作的工作量需要进行考虑。当然基于图片的分类同样需要进行数据库的建立。  
从计算量方面考虑，因为DeepCC需要Openpose的结果进行支持，因此st-gcn可以直接利用其获取的骨骼信息，因此虽然st-gcn需要滑窗，相比于直接对图像进行卷积分类，计算量应该差别不大。   
我们当前的工作是在最近一两天之内，给出一个基本的解决方案，使用何种算法。目前我们要进行的工作有如下：  
1. 根据以上的叙述，制作两种方案的算法流程图，简约且漂亮
2. 考察视频数据库建立的难度，评估其可行性
3. 思索上述方案的不足和可补充之处，做出补充  
